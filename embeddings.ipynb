{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447f553c-63e9-4de9-ac11-8939ee99ef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "# Modify OpenAI's API key and API base to use vLLM's API server.\n",
    "openai_api_key = \"\"\n",
    "openai_api_base = \"http://localhost:8000/v1\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "\n",
    "models = client.models.list()\n",
    "model = models.data[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa4255b-8897-4c08-b277-f998a74a4f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e34671-7076-44aa-904c-276ecb9271c8",
   "metadata": {},
   "source": [
    "Here we are using Amazon's review dataset that aims to identify whether the sentiment of a product review is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec976de-24bc-4b8d-85c6-3487cb2de9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"\"\n",
    "df = pd.read_csv(path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92c1997-58e2-4f4e-ad36-af584fa73b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"Time\", \"ProductId\", \"UserId\", \"Score\", \"Summary\", \"Text\"]]\n",
    "df = df.dropna()\n",
    "df[\"combined\"] = (\n",
    "    \"Title: \" + df.Summary.str.strip() + \"; Content: \" + df.Text.str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4ef8f7-5cd0-4a73-9b3d-ef3c7f4db826",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166e4709-af3a-4493-a02a-ef9d398a4cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# omit reviews that are too long to embed\n",
    "df[\"n_tokens\"] = df.combined.apply(lambda x: len(encoding.encode(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0386bf-0d06-4d12-b02d-a2ecb8f1878e",
   "metadata": {},
   "source": [
    "Wen are using GTE base model as the tokenizer, but the maximum context length is 768, which means there are certain responses that are too long at runtime. Therefore we are droping the indices here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83e67d5-134c-41e7-bbca-9005f0e179c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = []\n",
    "indices_to_drop = []\n",
    "import time\n",
    "a = time.time()\n",
    "for i in range(len(df)):\n",
    "    text = df[\"combined\"].iloc[i].replace(\"\\n\", \" \")\n",
    "    try:\n",
    "        response = client.embeddings.create(input=[text], model=\"iic/nlp_gte_sentence-embedding_english-base\")\n",
    "        \n",
    "    except openai.BadRequestError:\n",
    "        indices_to_drop.append(i)\n",
    "        continue\n",
    "    indices_to_drop.append(response.data[0].embedding)\n",
    "    #debug code\n",
    "    if i%1000 == 0:\n",
    "        print(time.time()-a)\n",
    "        print(len(indices_to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d1b88-f86b-4a09-98b4-39182037eeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"embedding\"]=embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fa0972-5ba2-4ca8-ae22-81f9336bf18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save = \"\"\n",
    "df.to_csv(path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649663d5-67eb-47d4-836b-ddca02d60560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
